# 모델 학습 시 고려사항 가이드

 모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하고 있지 못한다면 결코 의미있지 않습니다.   
 코드를 짜는 시간보다 고민하는 데에 더 많은 시간을 할애하셨으면 합니다. 또 결과를 통해 증명하기보다 본인의 논리를 믿고 따르는 습관을 들이면 좋겠습니다. 예상과 다르다면 다시 학습해가면 됩니다.

 모든 부분에 힘을 주실 필요가 없습니다.   

--------

모델을 학습할 때는 다양한 요소를 고려해야 합니다. 이는 데이터의 전처리부터 모델의 선택과 평가에 이르기까지 여러 단계에 걸쳐 영향을 미칩니다. 아래는 주요한 요소들을 설명합니다.

1. 결측치 처리
> 🧞‍♀️ 시각화 등으로 결측치를 확인해주세요. 각 열의 결측치를 대체한 방법과 왜 그 방법을 사용했는지에 관하여 논리적으로 서술해주세요.

* Cabin(방 호수) 컬럼 삭제: 결측치가 891개 중 687개로 나왔고, 방호수 데이터 자체가 분석에 큰 의미가 없다는 판단으로 삭제함.
* age의 왜도 첨도를 확인한 결과 정규분포를 따름
(첨도가 0.1782로 0에 가까워 평균적인 중앙 집중 분포를 보임)    
-> age의 결측치들은 mean값으로 대체.


2. 데이터 인코딩
범주형 변수는 모델이 이해할 수 있는 숫자 형태로 변환해야 합니다. 대표적인 방법으로는 Label Encoding(위계가 있는 경우)과 One-Hot Encoding(순서가 없는 경우)이 있습니다. 타겟 인코딩은 범주형 피처를 타겟 변수의 평균이나 비율로 인코딩하는 방법입니다. 타겟 변수가 특정 값일 확률을 사용하기도 합니다.

> 🧞‍♀️ 범주형 변수에 대해서 인코딩을 수행하셨다면 어떤 칼럼에 대해, 어떤 인코딩 방법을 사용하였는지 논리적으로 설명해주세요. (이때, 고려했던 인코딩 방법과 선택하지 않은 이유를 함께 제시해주세요.)

3. 데이터 스케일링

> 🧞‍♀️ 해당 데이터의 정규화 필요성에 대하여 논의해주세요. 해당 분포를 모델링에 적합한 형태로 변환하기 위해 사용한 스케일링 방식에 대해 설명해주세요.
> (ex. MinMax 스케일링은 이상치에 관하여 민감하므로, 그렇지 않은 ~ 방법을 사용했습니다.)
* Fare: 범위가 크고 이상치가 있는 경우 Min-Max를 쓰면 이상치 때문에 대부분의 값이 0 근처로 몰릴 가능성이 있음
-> 로그변환+표준화 방법 사용
(Fare의 최소값: 0, 최대값: 512.33 → 범위가 너무 큼 -> 로그변환 후 표준화 진행)
*Age: 평균 29.7, 표준편차 14.5로 비교적 정규분포에 가까움 → 그냥 표준화 


4. 데이터 왜도
왜도(skewness) 처리: 데이터가 비대칭적으로 분포되어 있을 때 로그 변환, 박스-콕스(Box-Cox) 변환 등을 사용해 왜도를 줄일 수 있습니다. 왜도가 크면 모델의 성능이 저하될 수 있습니다.

> 🧞‍♀️ 어떤 경우에 어떤 왜도 처리를 하는지 공부해보세요. 해당 데이터의 분포를 나타내는 시각화를 진행하고, 왜도를 수치로 표현해보세요.
타이타닉 데이터셋의 각 수치형 컬럼에는 왜도 처리가 필요한가요? 왜 그렇게 판단했나요?

5. 이상치(Outliers)
이상치 처리: 이상치는 모델에 부정적인 영향을 줄 수 있기 때문에 이를 식별하고 처리하는 것이 중요합니다. 이상치를 제거하거나, 다른 값으로 대체(예: 중앙값)하는 방법이 있습니다. 이상치가 반드시 잘못된 것은 아니므로 주의해야 합니다.

> 🧞‍♀️ 이상치를 처리하였나요? 어떤 기준으로 이상치를 판단하였나요?
* IQR기준
Fare: 13.02% (5~10% 기준을 초과 → 이상치가 많음!)
Age: 1.23% (전체 데이터의 5% 미만 → 이상치가 많지 않음)

-> Fare는 IQR 기준으로 이상치가 많으므로, 로그 변환 후 표준화하는 것이 적절함. 

6. 피처 선택 및 생성
피처 선택(Feature Selection): 모델 성능을 개선하거나 과적합을 방지하기 위해 불필요한 피처를 제거합니다. 이를 위해 통계적 방법(예: p-value), 모델 기반 방법(예: L1 정규화), 또는 피처 중요도를 활용합니다.

피처 생성(Feature Engineering): 모델 성능을 높이기 위해 새로운 피처를 생성할 수 있습니다. 예를 들어, 두 피처를 곱하거나 나누어 새로운 피처를 만들 수 있습니다.

> 🧞‍♀️ 새로 만든 피쳐가 있다면 자랑해주세요.

> 🧞‍♀️ 다중공선성이 있다고 판단되는 지표가 있었나요? 왜 그렇게 생각하셨으며, 어떻게 처리하셨나요?

7. 데이터 분할
훈련/검증/테스트 데이터 분할: 데이터셋을 훈련, 검증, 테스트 세트로 나누어 모델의 성능을 평가합니다. 일반적으로 70-80%를 훈련 데이터로 사용하고, 나머지를 검증과 테스트 데이터로 사용합니다.

> 🧞‍♀️ 데이터 분할 방법 중 K-Fold Cross-Validation과 Stratified K-fold Cross Validation에 대해 공부해보세요. 최종적으로 어떤 방법을 사용했는지, 왜 사용했는지에 대해 서술해주세요.
*0:1 비율이 대략 6:4 수준이므로 심각한 불균형은 아님
일반 K-Fold도 가능하지만, Stratified K-Fold를 사용하면 더 안정적인 평가가 가능
*일반적인 K-Fold를 사용하면 한 Fold에 특정 클래스가 몰려 학습이 왜곡될 수 있음
*Stratified K-Fold를 사용하면 각 Fold에서도 0과 1의 비율을 유지할 수 있어, 모델이 더 안정적으로 학습됨


8. 모델 선택
모델 유형 선택: 데이터의 특성에 따라 적합한 모델을 선택해야 합니다. 예를 들어, 선형 데이터에는 선형 회귀, 비선형 데이터에는 트리 기반 모델 등이 효과적일 수 있습니다.

> 🧞‍♀️ 해당 데이터가 예측하고자 하는 값이 어떤 유형인지에 관련하여 모델 선정의 논리성을 증명해주세요. 또한, 차안으로 선택할 수 있는 모델이 있다면 추천해주세요.


+ 하이퍼파라미터 튜닝: 각 모델의 하이퍼파라미터를 최적화하여 성능을 극대화할 수 있습니다. 그리드 서치(Grid Search)나 랜덤 서치(Random Search) 등의 방법이 도모됩니다.

9. 모델 평가
평가 지표 선택: 회귀 문제에서는 MSE, MAE, R², 분류 문제에서는 정확도, 정밀도, 재현율, F1-score 등을 사용하여 모델 성능을 평가합니다.
교차 검증(Cross-Validation): 데이터를 여러 번 분할하여 모델을 평가하는 방법입니다. 이를 통해 모델의 일반화 성능을 더 잘 평가할 수 있습니다.

평가 지표의 종류에 대해 공부해보세요. 
평가 지표 요약
🔹 1. 회귀 문제
- MSE (Mean Squared Error):평균 제곱 오차,오차가 클수록 페널티 증가 (이상치 영향 큼)
- MAE (Mean Absolute Error):평균 절대 오차,이상치 영향을 덜 받음
- R² (결정계수):모델의 설명력,	1에 가까울수록 좋음 (0이면 의미 없음)

=>이상치 많으면 MAE, 오차 중요하면 MSE, 모델 설명력은 R²


🔹 2. 분류 문제
- Accuracy (정확도):전체 데이터 중 맞춘 비율,클래스 불균형 시 부적절
- Precision (정밀도):	Positive 예측 중 실제 Positive 비율,	FP 줄이는 데 초점 (스팸 필터)
- Recall (재현율):	실제 Positive 중 모델이 맞춘 비율,	FN 줄이는 데 초점 (질병 진단)
- F1-score:	Precision & Recall 조화 평균,	클래스 불균형 시 유용
=>  FP 줄여야 하면 Precision, FN 줄여야 하면 Recall, 균형 맞추려면 F1-score


10. 과적합 방지
모델의 과적합을 방지하기 위한 여러 방법들이 있습니다.   
- 정규화(Regularization): L1, L2 정규화를 통해 모델의 복잡도를 조절하여 과적합을 방지합니다.   
- 드롭아웃(Dropout): 신경망에서 드롭아웃을 사용하여 과적합을 방지할 수 있습니다.   
- 얼리 스탑핑(Early Stopping): 검증 데이터의 성능이 더 이상 개선되지 않으면 훈련을 조기에 중지합니다.   

> 🧞‍♀️ 과적합 방지를 위해 도입한 방법이 있나요? 그 방법의 원리와 장점은 무엇인가요?

---
*출처: 4기 교육팀장님*
