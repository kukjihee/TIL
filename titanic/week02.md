# 📘 모델 학습 시 고려사항 가이드 📘 

모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하지 못한다면 결코 의미 있지 않습니다.

👉 **코드를 짜는 시간보다 고민하는 데 더 많은 시간을 할애하세요.**

👉 **결과에 휘둘리기보다, 본인의 논리를 세우고 검증하는 습관**을 들이세요. 예상과 다르다면 다시 학습해가면 됩니다.

> 모든 부분에 힘을 주실 필요는 없습니다. 핵심 포인트에 집중하세요.

---

## 1️⃣ 결측치 처리

- 결측치를 확인하고 적절한 방식으로 대체해야 합니다.
- 대체 방식: 평균, 중앙값, 최빈값, 혹은 도메인 지식 기반의 값.

> **실습**
>
> - 시각화를 통해 결측치 확인
> - 대체 방법과 그 이유를 논리적으로 설명하기
> - Age 컴럼: 분포를 보아 정규분포와 가까우므로 age의 결측치는 mean값으로 대체. 남녀가 다른 평균나이를 가지므로 남성과 여성을 나누어 각각의 평균값으로 대체한다.
> - Cabin 컬럼: 전체 891개 값 중 687개의 결측치가 나왔다. 방 호수 데이터는 생존율과 큰 관계가 없다고 판단하여 삭제한다.
> - Embarked 컬럼: 결측치가 2개뿐이기 때문에 가장 많은 비율을 차지하는 'S'로 대체한다. (S: 644, C:168, Q:77)
<br>


## 2️⃣ 데이터 인코딩

범주형 변수는 모델이 이해할 수 있는 숫자형으로 변환해야 합니다.

- **Label Encoding**: 순서가 있는 경우
- **One-Hot Encoding**: 순서가 없는 경우
- **Target Encoding**: 타겟 변수 평균/비율 기반



> **실습**
>
> - 어떤 컬럼에 어떤 인코딩 방법을 썼는지
> - 고려한 다른 방법과 선택하지 않은 이유
> - 라벨인코딩: Pclass, SibSp, Parch (순서척도)
> - 원핫인코딩: Embarked, Sex (명목척도)
<br>

## 3️⃣ 데이터 스케일링

- 데이터 분포를 모델링에 적합하게 변환하기 위해 필요.
- 예: MinMaxScaler, StandardScaler, RobustScaler



> **실습**
>
> - 정규화 필요성 논의
> - 선택한 스케일링 방법과 이유 설명
> - Age: StandardScaler ; 나이는 연속형, 정규분포에 가까운 분포를 따른다. 모델(로지스틱 회귀, KNN 등)에서 분산이 큰 피처는 가중치가 왜곡되기 때문에 표준화를 한다.(gpt참고..) 큰 극단치가 없기 때문에 MinMaxScaler 대신 표준화로 선택하였다.
> - Fare: RobustScaler ; 극단치(운임이 높은 승객)가 많아 표준화는 평균이 크게 왜곡될 수 있다. 따라서 이상치에 영향을 덜 받는 RobustScaler를 선택하였다.
> - 다른 변수들은 범주형이므로 스케일링을 할 필요가 없다고 판단하였다. 
<br>

## 4️⃣ 데이터 왜도 (Skewness)

- 비대칭 분포는 성능 저하를 유발
- 변환 방법: 로그 변환, Box-Cox 변환 등



> **실습**
>
> - 각 컬럼 분포 시각화
> - 왜도 수치 계산
> - 타이타닉 데이터셋 예시 → 어떤 컬럼이 왜도 처리 필요한지?
> - Age: 정규분포에 가깝다. 왜도 0.4~0.6 -> 왜도 처리 필요 없다.
> - Fare: 시각화 결과를 보아 극단치가 많이 존재한다. 왜도 4.5~5.0이상으로 매우 강한 양의 왜도를 보인다. => 로그 변환 수행
> - 범주형 변수는 왜도의 적용 대상이 아니다. 
<br>

## 5️⃣ 이상치 (Outliers)

- 이상치는 모델에 부정적 영향을 줄 수 있음
- 처리 방법: 제거, 대체(중앙값 등)



> **실습**
>
> - 이상치 기준을 제시
> - 처리 여부와 이유 설명
>
> - IQR 사용
> - Fare는 약 13.02% (116/891) -> 이상치가 모델에 영향을 줄 수 있을 만큼 많음
> - Age는 약 1.23% (11/891) -> 이상치가 많지 않음
> - 따라서 Age는 보존하고 Fare는 로그 변환을 한 후 RobustScaler을 통해 영향력을 완화함 (표준화를 할 수 있지만 이상치가 많기에 조금 더 왜곡이 없는 방법을 택했음)
<br>

## **6️⃣ 피처 선택 및 생성**

- **Feature Selection**: 불필요한 변수 제거 → 과적합 방지
- **Feature Engineering**: 새로운 변수 생성 (예: 곱셈/나눗셈으로 새로운 특징)



> **실습**
>
> - 새로 만든 피처가 있다면 설명하기
> - 다중공선성 여부 확인 & 처리 방법 제시 
<br>


## **7️⃣ 데이터 분할**

- 훈련/검증/테스트 데이터 분할
- 일반적으로 **70~80% → 훈련 / 나머지 → 검증·테스트**



> **실습**
>
> - K-Fold vs Stratified K-Fold 학습
> - 최종적으로 어떤 방법을 썼는지, 이유 설명
> - Stratified K-Fold를 택했음
단순 K-Fold도 사용 가능하지만 생존율이 약 38%로 불균형하기 때문에 보다 계층화된 방법이 더 적합하다 판단   
더불어서 Stratified K-fold를 통한다면 fold마다 생존자 비율이 일정하게 유지되며, 과적합 방지에도 효과적이라 생각
<br>


## 8️⃣ 모델 선택

- 데이터 특성에 맞는 모델 선정
  - 선형 관계 → 선형 회귀 ( Logistic )
  - 비선형 관계 → 트리 기반 모델 등 (Random Forest, XGBoost)



> **실습**
>
> - 예측하고자 하는 값의 유형에 따른 모델 선정 논리 제시
> - 대안 모델 추천 가능
>
> - 생존여부 예측을 목표로 잡았으므로, f1-score값을 중심으로 가장 높은 값을 내놓은 모델 선택
> - 📊 모델별 Accuracy / F1-score 비교   
Logistic Regression   Accuracy: 0.7962,  F1: 0.7545   
Random Forest         Accuracy: 0.7849,  F1: 0.7324   
SVM                   Accuracy: 0.8226,  F1: 0.7814   
KNN                   Accuracy: 0.8151,  F1: 0.7742   
XGBoost               Accuracy: 0.8302,  F1: 0.7826
> - ** f1-score가 가장 높은 XGBoost로 결정!!!!
> - 




- **하이퍼파라미터 튜닝**:

  Grid Search, Random Search 등으로 성능 최적화
<br>


## 9️⃣ 모델 평가

- 회귀: **MSE, MAE, R²**
- 분류: **Accuracy, Precision, Recall, F1-score**
- 교차 검증으로 일반화 성능 평가



> **실습**
>
> - 어떤 지표를 선택했는지와 그 이유 설명
>
> 분류 => 사망/생존 데이터 비율 뷴균형 => f1-SCORE 이용

<br>


## 🔟 과적합 방지

- **정규화**: L1, L2 규제로 복잡도 조절
- **Dropout**: 신경망에서 일부 노드 무작위 제거
- **Early Stopping**: 검증 성능이 개선되지 않으면 조기 종료



> **실습**
>
> - 과적합 방지를 위해 사용한 방법
> - 방법의 원리와 장점 설명

> - Random Forest의 경우 트리 깊이(max_depth)를 제한함으로써 모델 복잡도를 줄여 일반화 성능을 확보했다.
다만 Dropout이나 Early Stopping 같은 신경망 기반 기법은 사용하지 않았다.


📌 **출처**: 4기 교육팀장님
